{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82OvPKEiEqjc"
      },
      "source": [
        "# Введение в MapReduce модель на Python\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ2cvXLjICmI"
      },
      "source": [
        "from typing import NamedTuple # requires python 3.6+\n",
        "from typing import Iterator"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjPHumVwEyEg"
      },
      "source": [
        "def MAP(_, row:NamedTuple):\n",
        "  if (row.gender == 'female'):\n",
        "    yield (row.age, row)\n",
        "\n",
        "def REDUCE(age:str, rows:Iterator[NamedTuple]):\n",
        "  sum = 0\n",
        "  count = 0\n",
        "  for row in rows:\n",
        "    sum += row.social_contacts\n",
        "    count += 1\n",
        "  if (count > 0):\n",
        "    yield (age, sum/count)\n",
        "  else:\n",
        "    yield (age, 0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBKMgpG_ilaZ"
      },
      "source": [
        "Модель элемента данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv-XIjhTJPx3"
      },
      "source": [
        "class User(NamedTuple):\n",
        "  id: int\n",
        "  age: str\n",
        "  social_contacts: int\n",
        "  gender: str"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KV0Ze2vQgu5"
      },
      "source": [
        "input_collection = [\n",
        "    User(id=0, age=55, gender='male', social_contacts=20),\n",
        "    User(id=1, age=25, gender='female', social_contacts=240),\n",
        "    User(id=2, age=25, gender='female', social_contacts=500),\n",
        "    User(id=3, age=33, gender='female', social_contacts=800)\n",
        "]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFeqzyZxZIFZ"
      },
      "source": [
        "Функция RECORDREADER моделирует чтение элементов с диска или по сети."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5HR4E_GQoMJ"
      },
      "source": [
        "def RECORDREADER():\n",
        "  return [(u.id, u) for u in input_collection]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeEoWla-ROUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "189030ac-d2f6-463c-b8e1-44dd48aab812"
      },
      "source": [
        "list(RECORDREADER())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, User(id=0, age=55, social_contacts=20, gender='male')),\n",
              " (1, User(id=1, age=25, social_contacts=240, gender='female')),\n",
              " (2, User(id=2, age=25, social_contacts=500, gender='female')),\n",
              " (3, User(id=3, age=33, social_contacts=800, gender='female'))]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB8orgPSZs8M"
      },
      "source": [
        "def flatten(nested_iterable):\n",
        "  for iterable in nested_iterable:\n",
        "    for element in iterable:\n",
        "      yield element"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74oyvDLaRmd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0006bf90-0d99-4a67-818c-a97e739a1c79"
      },
      "source": [
        "map_output = flatten(map(lambda x: MAP(*x), RECORDREADER()))\n",
        "map_output = list(map_output) # materialize\n",
        "map_output"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(25, User(id=1, age=25, social_contacts=240, gender='female')),\n",
              " (25, User(id=2, age=25, social_contacts=500, gender='female')),\n",
              " (33, User(id=3, age=33, social_contacts=800, gender='female'))]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ncYDJ3-VzDn"
      },
      "source": [
        "def groupbykey(iterable):\n",
        "  t = {}\n",
        "  for (k2, v2) in iterable:\n",
        "    t[k2] = t.get(k2, []) + [v2]\n",
        "  return t.items()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKzY_6COWOA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad0b7424-90ae-44b9-f94b-9bb06834c6c6"
      },
      "source": [
        "shuffle_output = groupbykey(map_output)\n",
        "shuffle_output = list(shuffle_output)\n",
        "shuffle_output"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(25,\n",
              "  [User(id=1, age=25, social_contacts=240, gender='female'),\n",
              "   User(id=2, age=25, social_contacts=500, gender='female')]),\n",
              " (33, [User(id=3, age=33, social_contacts=800, gender='female')])]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlA7lkDDYL0t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648c8bc8-c97c-4cac-80f8-bd9b2dd45f09"
      },
      "source": [
        "reduce_output = flatten(map(lambda x: REDUCE(*x), shuffle_output))\n",
        "reduce_output = list(reduce_output)\n",
        "reduce_output"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(25, 370.0), (33, 800.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf6qhHEtd6bI"
      },
      "source": [
        "Все действия одним конвейером!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZaQGYxCdpw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c1254f9-ed63-4824-e624-fc67ebf7a8b2"
      },
      "source": [
        "list(flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER()))))))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(25, 370.0), (33, 800.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq3EWRIpwSiJ"
      },
      "source": [
        "# **MapReduce**\n",
        "Выделим общую для всех пользователей часть системы в отдельную функцию высшего порядка. Это наиболее простая модель MapReduce, без учёта распределённого хранения данных.\n",
        "\n",
        "Пользователь для решения своей задачи реализует RECORDREADER, MAP, REDUCE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1PZeQMwwVjc"
      },
      "source": [
        "def flatten(nested_iterable):\n",
        "  for iterable in nested_iterable:\n",
        "    for element in iterable:\n",
        "      yield element\n",
        "\n",
        "def groupbykey(iterable):\n",
        "  t = {}\n",
        "  for (k2, v2) in iterable:\n",
        "    t[k2] = t.get(k2, []) + [v2]\n",
        "  return t.items()\n",
        "\n",
        "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
        "  return flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER())))))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFIVrimep678"
      },
      "source": [
        "## Спецификация MapReduce\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "f (k1, v1) -> (k2,v2)*\n",
        "g (k2, v2*) -> (k3,v3)*\n",
        "\n",
        "mapreduce ((k1,v1)*) -> (k3,v3)*\n",
        "groupby ((k2,v2)*) -> (k2,v2*)*\n",
        "flatten (e2**) -> e2*\n",
        "\n",
        "mapreduce .map(f).flatten.groupby(k2).map(g).flatten\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtTFyqke3KGe"
      },
      "source": [
        "# Примеры"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNhh5763w5Vn"
      },
      "source": [
        "## SQL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkyurnvGxBGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f2c7c9-be1b-413c-a13a-b949e681acb3"
      },
      "source": [
        "from typing import NamedTuple # requires python 3.6+\n",
        "from typing import Iterator\n",
        "\n",
        "class User(NamedTuple):\n",
        "  id: int\n",
        "  age: str\n",
        "  social_contacts: int\n",
        "  gender: str\n",
        "\n",
        "input_collection = [\n",
        "    User(id=0, age=55, gender='male', social_contacts=20),\n",
        "    User(id=1, age=25, gender='female', social_contacts=240),\n",
        "    User(id=2, age=25, gender='female', social_contacts=500),\n",
        "    User(id=3, age=33, gender='female', social_contacts=800)\n",
        "]\n",
        "\n",
        "def MAP(_, row:NamedTuple):\n",
        "  if (row.gender == 'female'):\n",
        "    yield (row.age, row)\n",
        "\n",
        "def REDUCE(age:str, rows:Iterator[NamedTuple]):\n",
        "  sum = 0\n",
        "  count = 0\n",
        "  for row in rows:\n",
        "    sum += row.social_contacts\n",
        "    count += 1\n",
        "  if (count > 0):\n",
        "    yield (age, sum/count)\n",
        "  else:\n",
        "    yield (age, 0)\n",
        "\n",
        "def RECORDREADER():\n",
        "  return [(u.id, u) for u in input_collection]\n",
        "\n",
        "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
        "output = list(output)\n",
        "output"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(25, 370.0), (33, 800.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNKYIeerx0nY"
      },
      "source": [
        "## Matrix-Vector multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwcntRcCyi1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54e0e021-2186-441e-c821-c0caca0a1d81"
      },
      "source": [
        "from typing import Iterator\n",
        "import numpy as np\n",
        "\n",
        "mat = np.ones((5,4))\n",
        "vec = np.random.rand(4) # in-memory vector in all map tasks\n",
        "\n",
        "def MAP(coordinates:(int, int), value:int):\n",
        "  i, j = coordinates\n",
        "  yield (i, value*vec[j])\n",
        "\n",
        "def REDUCE(i:int, products:Iterator[NamedTuple]):\n",
        "  sum = 0\n",
        "  for p in products:\n",
        "    sum += p\n",
        "  yield (i, sum)\n",
        "\n",
        "def RECORDREADER():\n",
        "  for i in range(mat.shape[0]):\n",
        "    for j in range(mat.shape[1]):\n",
        "      yield ((i, j), mat[i,j])\n",
        "\n",
        "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
        "output = list(output)\n",
        "output"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, np.float64(1.6473836777529094)),\n",
              " (1, np.float64(1.6473836777529094)),\n",
              " (2, np.float64(1.6473836777529094)),\n",
              " (3, np.float64(1.6473836777529094)),\n",
              " (4, np.float64(1.6473836777529094))]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruZREYdi2o4O"
      },
      "source": [
        "## Inverted index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt9H9Alf3TYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94e0e667-3ca3-4b34-f52b-3301fea9110a"
      },
      "source": [
        "from typing import Iterator\n",
        "\n",
        "d1 = \"it is what it is\"\n",
        "d2 = \"what is it\"\n",
        "d3 = \"it is a banana\"\n",
        "documents = [d1, d2, d3]\n",
        "\n",
        "def RECORDREADER():\n",
        "  for (docid, document) in enumerate(documents):\n",
        "    yield (\"{}\".format(docid), document)\n",
        "\n",
        "def MAP(docId:str, body:str):\n",
        "  for word in set(body.split(' ')):\n",
        "    yield (word, docId)\n",
        "\n",
        "def REDUCE(word:str, docIds:Iterator[str]):\n",
        "  yield (word, sorted(docIds))\n",
        "\n",
        "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
        "output = list(output)\n",
        "output"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('what', ['0', '1']),\n",
              " ('is', ['0', '1', '2']),\n",
              " ('it', ['0', '1', '2']),\n",
              " ('a', ['2']),\n",
              " ('banana', ['2'])]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7az-6DA6qr2"
      },
      "source": [
        "## WordCount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN-nbtgG6uYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "332fc993-f273-466a-c6a2-0d662fcf064f"
      },
      "source": [
        "from typing import Iterator\n",
        "\n",
        "d1 = \"\"\"\n",
        "it is what it is\n",
        "it is what it is\n",
        "it is what it is\"\"\"\n",
        "d2 = \"\"\"\n",
        "what is it\n",
        "what is it\"\"\"\n",
        "d3 = \"\"\"\n",
        "it is a banana\"\"\"\n",
        "documents = [d1, d2, d3]\n",
        "\n",
        "def RECORDREADER():\n",
        "  for (docid, document) in enumerate(documents):\n",
        "    for (lineid, line) in enumerate(document.split('\\n')):\n",
        "      yield (\"{}:{}\".format(docid,lineid), line)\n",
        "\n",
        "def MAP(docId:str, line:str):\n",
        "  for word in line.split(\" \"):\n",
        "    yield (word, 1)\n",
        "\n",
        "def REDUCE(word:str, counts:Iterator[int]):\n",
        "  sum = 0\n",
        "  for c in counts:\n",
        "    sum += c\n",
        "  yield (word, sum)\n",
        "\n",
        "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
        "output = list(output)\n",
        "output"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 3), ('it', 9), ('is', 9), ('what', 5), ('a', 1), ('banana', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-jRAcYCAkkk"
      },
      "source": [
        "# MapReduce Distributed\n",
        "\n",
        "Добавляется в модель фабрика RECORDREARER-ов --- INPUTFORMAT, функция распределения промежуточных результатов по партициям PARTITIONER, и функция COMBINER для частичной аггрегации промежуточных результатов до распределения по новым партициям."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw-b-xJsApgW"
      },
      "source": [
        "def flatten(nested_iterable):\n",
        "  for iterable in nested_iterable:\n",
        "    for element in iterable:\n",
        "      yield element\n",
        "\n",
        "def groupbykey(iterable):\n",
        "  t = {}\n",
        "  for (k2, v2) in iterable:\n",
        "    t[k2] = t.get(k2, []) + [v2]\n",
        "  return t.items()\n",
        "\n",
        "def groupbykey_distributed(map_partitions, PARTITIONER):\n",
        "  global reducers\n",
        "  partitions = [dict() for _ in range(reducers)]\n",
        "  for map_partition in map_partitions:\n",
        "    for (k2, v2) in map_partition:\n",
        "      p = partitions[PARTITIONER(k2)]\n",
        "      p[k2] = p.get(k2, []) + [v2]\n",
        "  return [(partition_id, sorted(partition.items(), key=lambda x: x[0])) for (partition_id, partition) in enumerate(partitions)]\n",
        "\n",
        "def PARTITIONER(obj):\n",
        "  global reducers\n",
        "  return hash(obj) % reducers\n",
        "\n",
        "def MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, PARTITIONER=PARTITIONER, COMBINER=None):\n",
        "  map_partitions = map(lambda record_reader: flatten(map(lambda k1v1: MAP(*k1v1), record_reader)), INPUTFORMAT())\n",
        "  if COMBINER != None:\n",
        "    map_partitions = map(lambda map_partition: flatten(map(lambda k2v2: COMBINER(*k2v2), groupbykey(map_partition))), map_partitions)\n",
        "  reduce_partitions = groupbykey_distributed(map_partitions, PARTITIONER) # shuffle\n",
        "  reduce_outputs = map(lambda reduce_partition: (reduce_partition[0], flatten(map(lambda reduce_input_group: REDUCE(*reduce_input_group), reduce_partition[1]))), reduce_partitions)\n",
        "\n",
        "  print(\"{} key-value pairs were sent over a network.\".format(sum([len(vs) for (k,vs) in flatten([partition for (partition_id, partition) in reduce_partitions])])))\n",
        "  return reduce_outputs"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxirlf3XqZxY"
      },
      "source": [
        "## Спецификация MapReduce Distributed\n",
        "\n",
        "\n",
        "```\n",
        "f (k1, v1) -> (k2,v2)*\n",
        "g (k2, v2*) -> (k3,v3)*\n",
        "\n",
        "e1 (k1, v1)\n",
        "e2 (k2, v2)\n",
        "partition1 (k2, v2)*\n",
        "partition2 (k2, v2*)*\n",
        "\n",
        "flatmap (e1->e2*, e1*) -> partition1*\n",
        "groupby (partition1*) -> partition2*\n",
        "\n",
        "mapreduce ((k1,v1)*) -> (k3,v3)*\n",
        "mapreduce .flatmap(f).groupby(k2).flatmap(g)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWYw_CpbbY3C"
      },
      "source": [
        "## WordCount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR_zfGFkMZlp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edac71ec-134e-4f53-cc1f-0c4008d0b169"
      },
      "source": [
        "from typing import Iterator\n",
        "import numpy as np\n",
        "\n",
        "d1 = \"\"\"\n",
        "it is what it is\n",
        "it is what it is\n",
        "it is what it is\"\"\"\n",
        "d2 = \"\"\"\n",
        "what is it\n",
        "what is it\"\"\"\n",
        "d3 = \"\"\"\n",
        "it is a banana\"\"\"\n",
        "documents = [d1, d2, d3, d1, d2, d3]\n",
        "\n",
        "maps = 3\n",
        "reducers = 2\n",
        "\n",
        "def INPUTFORMAT():\n",
        "  global maps\n",
        "\n",
        "  def RECORDREADER(split):\n",
        "    for (docid, document) in enumerate(split):\n",
        "      for (lineid, line) in enumerate(document.split('\\n')):\n",
        "        yield (\"{}:{}\".format(docid,lineid), line)\n",
        "\n",
        "  split_size =  int(np.ceil(len(documents)/maps))\n",
        "  for i in range(0, len(documents), split_size):\n",
        "    yield RECORDREADER(documents[i:i+split_size])\n",
        "\n",
        "def MAP(docId:str, line:str):\n",
        "  for word in line.split(\" \"):\n",
        "    yield (word, 1)\n",
        "\n",
        "def REDUCE(word:str, counts:Iterator[int]):\n",
        "  sum = 0\n",
        "  for c in counts:\n",
        "    sum += c\n",
        "  yield (word, sum)\n",
        "\n",
        "# try to set COMBINER=REDUCER and look at the number of values sent over the network\n",
        "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, COMBINER=None)\n",
        "partitioned_output = [(partition_id, list(partition)) for (partition_id, partition) in partitioned_output]\n",
        "partitioned_output"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56 key-value pairs were sent over a network.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, [('', 6), ('a', 2), ('it', 18), ('what', 10)]),\n",
              " (1, [('banana', 2), ('is', 18)])]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCJGx8IQ87xS"
      },
      "source": [
        "## TeraSort"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2v8v1v_8_YR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8fa8b4b-c342-4dcd-c679-1705ffee30a8"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "input_values = np.random.rand(30)\n",
        "maps = 3\n",
        "reducers = 2\n",
        "min_value = 0.0\n",
        "max_value = 1.0\n",
        "\n",
        "def INPUTFORMAT():\n",
        "  global maps\n",
        "\n",
        "  def RECORDREADER(split):\n",
        "    for value in split:\n",
        "        yield (value, None)\n",
        "\n",
        "  split_size =  int(np.ceil(len(input_values)/maps))\n",
        "  for i in range(0, len(input_values), split_size):\n",
        "    yield RECORDREADER(input_values[i:i+split_size])\n",
        "\n",
        "def MAP(value:int, _):\n",
        "  yield (value, None)\n",
        "\n",
        "def PARTITIONER(key):\n",
        "  global reducers\n",
        "  global max_value\n",
        "  global min_value\n",
        "  bucket_size = (max_value-min_value)/reducers\n",
        "  bucket_id = 0\n",
        "  while((key>(bucket_id+1)*bucket_size) and ((bucket_id+1)*bucket_size<max_value)):\n",
        "    bucket_id += 1\n",
        "  return bucket_id\n",
        "\n",
        "def REDUCE(value:int, _):\n",
        "  yield (None,value)\n",
        "\n",
        "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, COMBINER=None, PARTITIONER=PARTITIONER)\n",
        "partitioned_output = [(partition_id, list(partition)) for (partition_id, partition) in partitioned_output]\n",
        "partitioned_output"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30 key-value pairs were sent over a network.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  [(None, np.float64(0.02156699686751784)),\n",
              "   (None, np.float64(0.06040865057589517)),\n",
              "   (None, np.float64(0.07435981345750187)),\n",
              "   (None, np.float64(0.07992943805683839)),\n",
              "   (None, np.float64(0.11666317728135189)),\n",
              "   (None, np.float64(0.14471009828544779)),\n",
              "   (None, np.float64(0.18603756389959636)),\n",
              "   (None, np.float64(0.21390699995992013)),\n",
              "   (None, np.float64(0.2341704067260818)),\n",
              "   (None, np.float64(0.26401758603436276)),\n",
              "   (None, np.float64(0.29866212060733677)),\n",
              "   (None, np.float64(0.3062007074495994)),\n",
              "   (None, np.float64(0.3214055405258347)),\n",
              "   (None, np.float64(0.3639695304231413)),\n",
              "   (None, np.float64(0.41799931195989104)),\n",
              "   (None, np.float64(0.4601542553288016))]),\n",
              " (1,\n",
              "  [(None, np.float64(0.5900282738578496)),\n",
              "   (None, np.float64(0.6245056806045802)),\n",
              "   (None, np.float64(0.6354423277211749)),\n",
              "   (None, np.float64(0.6654615958405462)),\n",
              "   (None, np.float64(0.7744941405923091)),\n",
              "   (None, np.float64(0.7846447338419545)),\n",
              "   (None, np.float64(0.7893987882239812)),\n",
              "   (None, np.float64(0.792865364534014)),\n",
              "   (None, np.float64(0.8135078427172715)),\n",
              "   (None, np.float64(0.8404074192524215)),\n",
              "   (None, np.float64(0.911435895198984)),\n",
              "   (None, np.float64(0.9695529926981132)),\n",
              "   (None, np.float64(0.9878922330850091)),\n",
              "   (None, np.float64(0.9951380724011583))])]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQhoJaVZI93G"
      },
      "source": [],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy65YJTH99iT"
      },
      "source": [
        "# Упражнения\n",
        "Упражнения взяты из Rajaraman A., Ullman J. D. Mining of massive datasets. – Cambridge University Press, 2011.\n",
        "\n",
        "\n",
        "Для выполнения заданий переопределите функции RECORDREADER, MAP, REDUCE. Для модели распределённой системы может потребоваться переопределение функций PARTITION и COMBINER."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfvAeZm3S8S8"
      },
      "source": [
        "### Максимальное значение ряда\n",
        "\n",
        "Разработайте MapReduce алгоритм, который находит максимальное число входного списка чисел."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GRA1JR-Tkbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b297eee-d347-4de1-ddb1-2665bb582538"
      },
      "source": [
        "from typing import Iterator\n",
        "import numpy as np\n",
        "\n",
        "# --- данные ---\n",
        "rng = np.random.default_rng(42)\n",
        "arr = rng.integers(low=-50, high=200, size=50).tolist()\n",
        "\n",
        "n_maps = 3\n",
        "\n",
        "def INPUTFORMAT():\n",
        "    \"\"\"Разбиваем вход на n_maps частей и отдаём генераторы записей.\"\"\"\n",
        "    def record_reader(chunk):\n",
        "        for value in chunk:\n",
        "            yield (0, value)\n",
        "    for chunk in np.array_split(arr, n_maps):\n",
        "        yield record_reader(chunk.tolist())\n",
        "\n",
        "def MAP(_, value: int):\n",
        "    # Все значения под один ключ -> глобальный максимум\n",
        "    yield (\"GLOBAL_MAX\", value)\n",
        "\n",
        "def REDUCE(key: str, values: Iterator[int]):\n",
        "    best = None\n",
        "    for v in values:\n",
        "        if best is None or v > best:\n",
        "            best = v\n",
        "    yield (key, best)\n",
        "\n",
        "# локально возьмём максимум на каждом mapper'е\n",
        "parts = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, COMBINER=REDUCE)\n",
        "\n",
        "parts = [(pid, list(part)) for (pid, part) in parts]\n",
        "out = [kv for (pid, part) in parts for kv in part]\n",
        "\n",
        "out, \"python max =\", max(arr)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 key-value pairs were sent over a network.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('GLOBAL_MAX', 193)], 'python max =', 193)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k86bXnqZTk-U"
      },
      "source": [
        "### Арифметическое среднее\n",
        "\n",
        "Разработайте MapReduce алгоритм, который находит арифметическое среднее.\n",
        "\n",
        "$$\\overline{X} = \\frac{1}{n}\\sum_{i=0}^{n} x_i$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPoY5pkfUNZf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb05225-f9ad-490d-acc6-58dd7e456285"
      },
      "source": [
        "from typing import Iterator, Tuple\n",
        "import numpy as np\n",
        "\n",
        "# --- данные ---\n",
        "rng = np.random.default_rng(42)\n",
        "arr = rng.integers(low=-50, high=200, size=50).tolist()\n",
        "\n",
        "n_maps = 3\n",
        "\n",
        "def INPUTFORMAT():\n",
        "    \"\"\"Раздаём вход на n_maps кусков.\"\"\"\n",
        "    def record_reader(chunk):\n",
        "        for v in chunk:\n",
        "            yield (None, v)\n",
        "\n",
        "    for chunk in np.array_split(arr, n_maps):\n",
        "        yield record_reader(chunk.tolist())\n",
        "\n",
        "def MAP(_, value: int):\n",
        "    # Для среднего передаём (значение, 1)\n",
        "    yield (\"AVG\", (value, 1))\n",
        "\n",
        "def REDUCE(key: str, pairs: Iterator[Tuple[int, int]]):\n",
        "    total = 0\n",
        "    cnt = 0\n",
        "    for s, c in pairs:\n",
        "        total += s\n",
        "        cnt += c\n",
        "    yield (key, (total, cnt))\n",
        "\n",
        "# combiner тот же: локально суммируем (sum, count), уменьшаем трафик\n",
        "parts = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, COMBINER=REDUCE)\n",
        "\n",
        "parts = [(pid, list(part)) for (pid, part) in parts]\n",
        "out = [kv for (pid, part) in parts for kv in part]\n",
        "total_sum = 0\n",
        "total_cnt = 0\n",
        "for _, (s, c) in out:\n",
        "    total_sum += s\n",
        "    total_cnt += c\n",
        "\n",
        "mr_avg = total_sum / total_cnt\n",
        "\n",
        "mr_avg, \"python mean =\", (sum(arr) / len(arr))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 key-value pairs were sent over a network.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84.76, 'python mean =', 84.76)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xanzszhsIlLe"
      },
      "source": [
        "### GroupByKey на основе сортировки\n",
        "\n",
        "Реализуйте groupByKey на основе сортировки, проверьте его работу на примерах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQPn3USsIkEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69572288-b09c-4059-9e52-d55fb3f24ce4"
      },
      "source": [
        "from typing import Iterable, Iterator, Tuple, List, TypeVar\n",
        "from itertools import groupby\n",
        "from operator import itemgetter\n",
        "\n",
        "K = TypeVar(\"K\")\n",
        "V = TypeVar(\"V\")\n",
        "\n",
        "def groupByKey_sorted(pairs: Iterable[Tuple[K, V]]) -> Iterator[Tuple[K, List[V]]]:\n",
        "    \"\"\"\n",
        "    Группирует (key, value) по key через сортировку:\n",
        "    sort -> groupby -> собираем список значений.\n",
        "    \"\"\"\n",
        "    pairs_sorted = sorted(pairs, key=itemgetter(0))  # сортируем по key\n",
        "\n",
        "    for k, group in groupby(pairs_sorted, key=itemgetter(0)):\n",
        "        yield (k, [v for _, v in group])\n",
        "\n",
        "\n",
        "# ---- проверки на примерах ----\n",
        "example1 = [(\"b\", 2), (\"a\", 1), (\"b\", 3), (\"a\", 7), (\"c\", 10)]\n",
        "print(\"input:\", example1)\n",
        "print(\"grouped:\", list(groupByKey_sorted(example1)))\n",
        "\n",
        "example2 = [(\"x\", 1)]\n",
        "print(\"\\ninput:\", example2)\n",
        "print(\"grouped:\", list(groupByKey_sorted(example2)))\n",
        "\n",
        "example3 = []\n",
        "print(\"\\ninput:\", example3)\n",
        "print(\"grouped:\", list(groupByKey_sorted(example3)))\n",
        "\n",
        "example4 = [(2, \"u\"), (1, \"a\"), (2, \"v\"), (1, \"b\"), (3, \"z\")]\n",
        "print(\"\\ninput:\", example4)\n",
        "print(\"grouped:\", list(groupByKey_sorted(example4)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: [('b', 2), ('a', 1), ('b', 3), ('a', 7), ('c', 10)]\n",
            "grouped: [('a', [1, 7]), ('b', [2, 3]), ('c', [10])]\n",
            "\n",
            "input: [('x', 1)]\n",
            "grouped: [('x', [1])]\n",
            "\n",
            "input: []\n",
            "grouped: []\n",
            "\n",
            "input: [(2, 'u'), (1, 'a'), (2, 'v'), (1, 'b'), (3, 'z')]\n",
            "grouped: [(1, ['a', 'b']), (2, ['u', 'v']), (3, ['z'])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SgEjCZyGnu6"
      },
      "source": [
        "### Drop duplicates (set construction, unique elements, distinct)\n",
        "\n",
        "Реализуйте распределённую операцию исключения дубликатов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okjbyApjGhMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4512b963-6ab0-40b8-df76-952987150328"
      },
      "source": [
        "from typing import Iterator\n",
        "import numpy as np\n",
        "\n",
        "# --- данные ---\n",
        "rng = np.random.default_rng(42)\n",
        "arr = rng.integers(low=0, high=10, size=30).tolist()  # специально с повторениями\n",
        "\n",
        "n_maps = 3\n",
        "n_reducers = 2\n",
        "\n",
        "def INPUTFORMAT():\n",
        "    def record_reader(chunk):\n",
        "        for v in chunk:\n",
        "            yield (None, v)\n",
        "\n",
        "    for chunk in np.array_split(arr, n_maps):\n",
        "        yield record_reader(chunk.tolist())\n",
        "\n",
        "def MAP(_, value: int):\n",
        "    # ключом делаем сам элемент\n",
        "    yield (value, 1)\n",
        "\n",
        "def COMBINER(key: int, values: Iterator[int]):\n",
        "    # если элемент есть хотя бы раз в сплите — оставляем один\n",
        "    yield (key, 1)\n",
        "\n",
        "def REDUCE(key: int, values: Iterator[int]):\n",
        "    # элемент присутствует -> выдаём его один раз\n",
        "    yield key\n",
        "\n",
        "parts = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, COMBINER=COMBINER)\n",
        "\n",
        "parts = [(pid, list(part)) for (pid, part) in parts]\n",
        "out = [kv for (pid, part) in parts for kv in part]\n",
        "\n",
        "sorted(out), \"python distinct =\", sorted(set(arr))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 key-value pairs were sent over a network.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
              " 'python distinct =',\n",
              " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7sRGoTXuJze"
      },
      "source": [
        "#Операторы реляционной алгебры\n",
        "### Selection (Выборка)\n",
        "\n",
        "**The Map Function**: Для  каждого кортежа $t \\in R$ вычисляется истинность предиката $C$. В случае истины создаётся пара ключ-значение $(t, t)$. В паре ключ и значение одинаковы, равны $t$.\n",
        "\n",
        "**The Reduce Function:** Роль функции Reduce выполняет функция идентичности, которая возвращает то же значение, что получила на вход.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nKIKe59uIfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc826e9-5c2c-4b6d-f0f7-e4cbb5236b70"
      },
      "source": [
        "from typing import Iterator, Tuple, List\n",
        "import math\n",
        "\n",
        "# Отношение R: (name, age, city)\n",
        "R: List[Tuple[str, int, str]] = [\n",
        "    (\"Irishka\", 5, \"Samara\"),\n",
        "    (\"Ilya\", 20, \"Kazan\"),\n",
        "    (\"Dima\", 11, \"Samarkant\"),\n",
        "]\n",
        "\n",
        "mappers = 2\n",
        "\n",
        "def predicate(t: Tuple[str, int, str]) -> bool:\n",
        "    # условие C(t): возраст >= 10\n",
        "    return int(t[1]) >= 10\n",
        "\n",
        "def INPUTFORMAT():\n",
        "    \"\"\"Разбиваем R на несколько частей и отдаём генераторы записей.\"\"\"\n",
        "    def record_reader(chunk: List[Tuple[str, int, str]]):\n",
        "        for t in chunk:\n",
        "            yield (None, t)\n",
        "\n",
        "    split_size = int(math.ceil(len(R) / mappers))\n",
        "    for i in range(0, len(R), split_size):\n",
        "        yield record_reader(R[i:i + split_size])\n",
        "\n",
        "def MAP(_, t: Tuple[str, int, str]):\n",
        "    # Если предикат истинен -> (t, t)\n",
        "    if predicate(t):\n",
        "        yield (t, t)\n",
        "\n",
        "def REDUCE(key: Tuple[str, int, str], values: Iterator[Tuple[str, int, str]]):\n",
        "    # Identity reduce: вернуть то, что пришло\n",
        "    for v in values:\n",
        "        yield (key, v)\n",
        "\n",
        "parts = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE)\n",
        "parts = [(pid, list(part)) for (pid, part) in parts]\n",
        "\n",
        "selected = [t for (pid, part) in parts for (t, _) in part]\n",
        "selected, \"python selection =\", [t for t in R if predicate(t)]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 key-value pairs were sent over a network.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('Dima', 11, 'Samarkant'), ('Ilya', 20, 'Kazan')],\n",
              " 'python selection =',\n",
              " [('Ilya', 20, 'Kazan'), ('Dima', 11, 'Samarkant')])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w27Ca-_Ku85V"
      },
      "source": [
        "### Projection (Проекция)\n",
        "\n",
        "Проекция на множество атрибутов $S$.\n",
        "\n",
        "**The Map Function:** Для каждого кортежа $t \\in R$ создайте кортеж $t′$, исключая  из $t$ те значения, атрибуты которых не принадлежат  $S$. Верните пару $(t′, t′)$.\n",
        "\n",
        "**The Reduce Function:** Для каждого ключа $t′$, созданного любой Map задачей, вы получаете одну или несколько пар $(t′, t′)$. Reduce функция преобразует $(t′, [t′, t′, . . . , t′])$ в $(t′, t′)$, так, что для ключа $t′$ возвращается одна пара  $(t′, t′)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEvuY4GqvhS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3688c0-9d1f-42c3-ec7f-89ffce350ec3"
      },
      "source": [
        "from typing import Iterator, Tuple, List\n",
        "import math\n",
        "\n",
        "# Отношение R: (name, age, city)\n",
        "R: List[Tuple[str, int, str]] = [\n",
        "    (\"Irishka\", 5, \"Samara\"),\n",
        "    (\"Ilya\", 20, \"Kazan\"),\n",
        "    (\"Dima\", 11, \"Samarkant\"),\n",
        "    (\"Olya\", 31, \"Kazan\"),        # добавила, чтобы показать дубликат по городу\n",
        "]\n",
        "\n",
        "mappers = 2\n",
        "\n",
        "# Проекция на множество атрибутов S (индексы столбцов)\n",
        "S_idx = (2,)   # например, только город\n",
        "\n",
        "def project(t: Tuple[str, int, str], idxs: Tuple[int, ...]) -> Tuple:\n",
        "    return tuple(t[i] for i in idxs)\n",
        "\n",
        "def INPUTFORMAT():\n",
        "    \"\"\"Разбиваем R на несколько частей и отдаём генераторы записей.\"\"\"\n",
        "    def record_reader(chunk: List[Tuple[str, int, str]]):\n",
        "        for t in chunk:\n",
        "            yield (None, t)\n",
        "\n",
        "    split_size = int(math.ceil(len(R) / mappers))\n",
        "    for i in range(0, len(R), split_size):\n",
        "        yield record_reader(R[i:i + split_size])\n",
        "\n",
        "def MAP(_, t: Tuple[str, int, str]):\n",
        "    # строим t' и возвращаем (t', t')\n",
        "    t2 = project(t, S_idx)\n",
        "    yield (t2, t2)\n",
        "\n",
        "def REDUCE(t2: Tuple, _values: Iterator[Tuple]):\n",
        "    # для каждого ключа t' вернуть ровно одну пару (t', t')\n",
        "    yield (t2, t2)\n",
        "\n",
        "parts = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE)\n",
        "parts = [(pid, list(part)) for (pid, part) in parts]\n",
        "\n",
        "projection = [t2 for (pid, part) in parts for (t2, _) in part]\n",
        "\n",
        "# сравнение с питоном (distinct после projection)\n",
        "projection_sorted = sorted(projection)\n",
        "python_sorted = sorted(set(project(t, S_idx) for t in R))\n",
        "\n",
        "projection_sorted, \"python projection =\", python_sorted"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 key-value pairs were sent over a network.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('Kazan',), ('Samara',), ('Samarkant',)],\n",
              " 'python projection =',\n",
              " [('Kazan',), ('Samara',), ('Samarkant',)])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gau6lKXvn2R"
      },
      "source": [
        "### Union (Объединение)\n",
        "\n",
        "**The Map Function:** Превратите каждый входной кортеж $t$ в пару ключ-значение $(t, t)$.\n",
        "\n",
        "**The Reduce Function:** С каждым ключом $t$ будет ассоциировано одно или два значений. В обоих случаях создайте $(t, t)$ в качестве выходного значения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sns7a5agv3nw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70beecdc-fe71-41ce-f282-83b33d40a2a2"
      },
      "source": [
        "from typing import Iterator, Tuple, List\n",
        "import math\n",
        "\n",
        "# Два отношения одинаковой схемы\n",
        "R: List[Tuple[str, int, str]] = [\n",
        "    (\"Irishka\", 5, \"Samara\"),\n",
        "    (\"Ilya\", 20, \"Kazan\"),\n",
        "    (\"Dima\", 11, \"Samarkant\"),\n",
        "]\n",
        "\n",
        "S: List[Tuple[str, int, str]] = [\n",
        "    (\"Ilya\", 20, \"Kazan\"),        # пересечение с R\n",
        "    (\"Olga\", 31, \"Moscow\"),\n",
        "    (\"Timur\", 19, \"Kazan\"),\n",
        "]\n",
        "\n",
        "mappers = 2\n",
        "\n",
        "# будем склеивать R и S в один поток для MR\n",
        "all_rows = R + S\n",
        "\n",
        "def INPUTFORMAT():\n",
        "    def record_reader(chunk):\n",
        "        for t in chunk:\n",
        "            yield (None, t)\n",
        "\n",
        "    split_size = int(math.ceil(len(all_rows) / mappers))\n",
        "    for i in range(0, len(all_rows), split_size):\n",
        "        yield record_reader(all_rows[i:i + split_size])\n",
        "\n",
        "def MAP(_, t: Tuple[str, int, str]):\n",
        "    # каждый кортеж t -> (t, t)\n",
        "    yield (t, t)\n",
        "\n",
        "def REDUCE(t: Tuple[str, int, str], _values: Iterator[Tuple[str, int, str]]):\n",
        "    # может прийти 1 или 2 значения, но union возвращает t один раз\n",
        "    yield (t, t)\n",
        "\n",
        "parts = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE)\n",
        "parts = [(pid, list(part)) for (pid, part) in parts]\n",
        "\n",
        "union_res = sorted([t for (pid, part) in parts for (t, _) in part])\n",
        "\n",
        "# проверка питоном: union как множество\n",
        "python_union = sorted(set(R).union(set(S)))\n",
        "\n",
        "union_res, \"python union =\", python_union"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 key-value pairs were sent over a network.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('Dima', 11, 'Samarkant'),\n",
              "  ('Ilya', 20, 'Kazan'),\n",
              "  ('Irishka', 5, 'Samara'),\n",
              "  ('Olga', 31, 'Moscow'),\n",
              "  ('Timur', 19, 'Kazan')],\n",
              " 'python union =',\n",
              " [('Dima', 11, 'Samarkant'),\n",
              "  ('Ilya', 20, 'Kazan'),\n",
              "  ('Irishka', 5, 'Samara'),\n",
              "  ('Olga', 31, 'Moscow'),\n",
              "  ('Timur', 19, 'Kazan')])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ8TuEbjv4J8"
      },
      "source": [
        "### Intersection (Пересечение)\n",
        "\n",
        "**The Map Function:** Превратите каждый кортеж $t$ в пары ключ-значение $(t, t)$.\n",
        "\n",
        "**The Reduce Function:** Если для ключа $t$ есть список из двух элементов $[t, t]$ $-$ создайте пару $(t, t)$. Иначе, ничего не создавайте."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKlBZh4IwERR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c3a1a29-be8c-4bce-c6d0-2aaa26ddfa4b"
      },
      "source": [
        "from typing import Iterator, Tuple, List\n",
        "import math\n",
        "\n",
        "R: List[Tuple[str, int, str]] = [\n",
        "    (\"Irishka\", 5, \"Samara\"),\n",
        "    (\"Ilya\", 20, \"Kazan\"),\n",
        "    (\"Dima\", 11, \"Samarkant\"),\n",
        "]\n",
        "\n",
        "S: List[Tuple[str, int, str]] = [\n",
        "    (\"Ilya\", 20, \"Kazan\"),        # есть в пересечении\n",
        "    (\"Olga\", 31, \"Moscow\"),\n",
        "    (\"Timur\", 19, \"Kazan\"),\n",
        "]\n",
        "\n",
        "mappers = 2\n",
        "\n",
        "# помечаем источник, чтобы intersection работал корректно даже если будут повторы\n",
        "all_rows = [(\"R\", t) for t in R] + [(\"S\", t) for t in S]\n",
        "\n",
        "def INPUTFORMAT():\n",
        "    def record_reader(chunk):\n",
        "        for src, t in chunk:\n",
        "            yield (src, t)\n",
        "\n",
        "    split_size = int(math.ceil(len(all_rows) / mappers))\n",
        "    for i in range(0, len(all_rows), split_size):\n",
        "        yield record_reader(all_rows[i:i + split_size])\n",
        "\n",
        "def MAP(src: str, t: Tuple[str, int, str]):\n",
        "    # ключ — сам кортеж, значение — источник\n",
        "    yield (t, src)\n",
        "\n",
        "def REDUCE(t: Tuple[str, int, str], srcs: Iterator[str]):\n",
        "    seen = set()\n",
        "    for s in srcs:\n",
        "        seen.add(s)\n",
        "        if len(seen) == 2:    # есть и R, и S\n",
        "            yield (t, t)\n",
        "            return\n",
        "\n",
        "parts = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE)\n",
        "parts = [(pid, list(part)) for (pid, part) in parts]\n",
        "\n",
        "inter = sorted([t for (pid, part) in parts for (t, _) in part])\n",
        "\n",
        "python_inter = sorted(set(R).intersection(set(S)))\n",
        "\n",
        "inter, \"python intersection =\", python_inter"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 key-value pairs were sent over a network.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('Ilya', 20, 'Kazan')], 'python intersection =', [('Ilya', 20, 'Kazan')])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVOpqoY3wE5k"
      },
      "source": [
        "### Difference (Разница)\n",
        "\n",
        "**The Map Function:** Для кортежа $t \\in R$, создайте пару $(t, R)$, и для кортежа $t \\in S$, создайте пару $(t, S)$. Задумка заключается в том, чтобы значение пары было именем отношения $R$ or $S$, которому принадлежит кортеж (а лучше, единичный бит, по которому можно два отношения различить $R$ or $S$), а не весь набор атрибутов отношения.\n",
        "\n",
        "**The Reduce Function:** Для каждого ключа $t$, если соответствующее значение является списком $[R]$, создайте пару $(t, t)$. В иных случаях не предпринимайте действий."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE_AC09lwZIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef0c68a-8b12-4ff5-9efa-0991109c9493"
      },
      "source": [
        "from typing import Iterator, Tuple, List\n",
        "import math\n",
        "\n",
        "R: List[Tuple[str, int]] = [\n",
        "    (\"a\", 1),\n",
        "    (\"b\", 2),\n",
        "    (\"c\", 3),\n",
        "]\n",
        "\n",
        "S: List[Tuple[str, int]] = [\n",
        "    (\"b\", 2),\n",
        "    (\"d\", 4),\n",
        "]\n",
        "\n",
        "mappers = 2\n",
        "reducers = 2\n",
        "\n",
        "# помечаем источник\n",
        "all_rows = [(\"R\", t) for t in R] + [(\"S\", t) for t in S]\n",
        "\n",
        "def INPUTFORMAT():\n",
        "    def record_reader(chunk):\n",
        "        for src, t in chunk:\n",
        "            yield (src, t)\n",
        "\n",
        "    split_size = int(math.ceil(len(all_rows) / mappers))\n",
        "    for i in range(0, len(all_rows), split_size):\n",
        "        yield record_reader(all_rows[i:i + split_size])\n",
        "\n",
        "def MAP(src: str, t: Tuple[str, int]):\n",
        "    yield (t, src)\n",
        "\n",
        "def REDUCE(t: Tuple[str, int], rels: Iterator[str]):\n",
        "    rels_set = set(rels)\n",
        "    # оставить только если есть в R и нет в S\n",
        "    if rels_set == {\"R\"}:\n",
        "        yield (t, t)\n",
        "\n",
        "parts = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE)\n",
        "parts = [(pid, list(part)) for (pid, part) in parts]\n",
        "\n",
        "diff = sorted([t for (pid, part) in parts for (t, _) in part])\n",
        "\n",
        "python_diff = sorted(set(R) - set(S))\n",
        "\n",
        "diff, \"python R-S =\", python_diff"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 key-value pairs were sent over a network.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('a', 1), ('c', 3)], 'python R-S =', [('a', 1), ('c', 3)])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8I58V2VwhSm"
      },
      "source": [
        "### Natural Join\n",
        "\n",
        "**The Map Function:** Для каждого кортежа $(a, b)$ отношения $R$, создайте пару $(b,(R, a))$. Для каждого кортежа $(b, c)$ отношения $S$, создайте пару $(b,(S, c))$.\n",
        "\n",
        "**The Reduce Function:** Каждый ключ $b$ будет асоциирован со списком пар, которые принимают форму либо $(R, a)$, либо $(S, c)$. Создайте все пары, одни, состоящие из  первого компонента $R$, а другие, из первого компонента $S$, то есть $(R, a)$ и $(S, c)$. На выходе вы получаете последовательность пар ключ-значение из списков ключей и значений. Ключ не нужен. Каждое значение, это тройка $(a, b, c)$ такая, что $(R, a)$ и $(S, c)$ это принадлежат входному списку значений."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHiuuTctw86I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd95206-9f8e-411e-9e26-a0b626084b16"
      },
      "source": [
        "from typing import Iterator, Tuple, List\n",
        "\n",
        "# R(a, b)\n",
        "R: List[Tuple[str, int]] = [\n",
        "    (\"x1\", 1),\n",
        "    (\"x2\", 2),\n",
        "    (\"x3\", 1),\n",
        "]\n",
        "\n",
        "# S(b, c)\n",
        "S: List[Tuple[int, str]] = [\n",
        "    (1, \"A\"),\n",
        "    (2, \"B\"),\n",
        "    (3, \"C\"),\n",
        "]\n",
        "\n",
        "def RECORDREADER():\n",
        "    for a, b in R:\n",
        "        yield (\"R\", (a, b))\n",
        "    for b, c in S:\n",
        "        yield (\"S\", (b, c))\n",
        "\n",
        "def MAP(rel, tup):\n",
        "    if rel == \"R\":\n",
        "        a, b = tup\n",
        "        yield (b, (\"R\", a))\n",
        "    else:\n",
        "        b, c = tup\n",
        "        yield (b, (\"S\", c))\n",
        "\n",
        "def REDUCE(b, values):\n",
        "    r_vals = []\n",
        "    s_vals = []\n",
        "\n",
        "    for tag, val in values:\n",
        "        if tag == \"R\":\n",
        "            r_vals.append(val)\n",
        "        else:\n",
        "            s_vals.append(val)\n",
        "\n",
        "    for a in r_vals:\n",
        "        for c in s_vals:\n",
        "            yield (None, (a, b, c))\n",
        "\n",
        "join_res = [v for (_, v) in MapReduce(RECORDREADER, MAP, REDUCE)]\n",
        "sorted(join_res)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('x1', 1, 'A'), ('x2', 2, 'B'), ('x3', 1, 'A')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYdlr0YUxE27"
      },
      "source": [
        "### Grouping and Aggregation (Группировка и аггрегация)\n",
        "\n",
        "**The Map Function:** Для каждого кортежа $(a, b, c$) создайте пару $(a, b)$.\n",
        "\n",
        "**The Reduce Function:** Ключ представляет ту или иную группу. Примение аггрегирующую операцию $\\theta$ к списку значений $[b1, b2, . . . , bn]$ ассоциированных с ключом $a$. Возвращайте в выходной поток $(a, x)$, где $x$ результат применения  $\\theta$ к списку. Например, если $\\theta$ это $SUM$, тогда $x = b1 + b2 + · · · + bn$, а если $\\theta$ is $MAX$, тогда $x$ это максимальное из значений $b1, b2, . . . , bn$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLPckfEGxico",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffbf368d-4a5a-4a37-cfe1-399bb8d7189f"
      },
      "source": [
        "from typing import Iterator, Tuple, List\n",
        "\n",
        "# (a, b, c)\n",
        "R: List[Tuple[str, int, str]] = [\n",
        "    (\"A\", 10, \"x\"),\n",
        "    (\"B\", 5, \"y\"),\n",
        "    (\"A\", 7, \"z\"),\n",
        "    (\"B\", 3, \"k\"),\n",
        "    (\"C\", 8, \"m\"),\n",
        "]\n",
        "def RECORDREADER():\n",
        "    for t in R:\n",
        "        yield (None, t)\n",
        "\n",
        "def MAP(_, t: Tuple[str, int, str]):\n",
        "    a, b, _ = t\n",
        "    yield (a, b)\n",
        "\n",
        "def REDUCE(a: str, values: Iterator[int]):\n",
        "    total = 0\n",
        "    for v in values:\n",
        "        total += v\n",
        "    yield (a, total)\n",
        "\n",
        "group_sum = sorted([kv for kv in MapReduce(RECORDREADER, MAP, REDUCE)])\n",
        "group_sum"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('A', 17), ('B', 8), ('C', 8)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIrRgvG4RIS4"
      },
      "source": [
        "### Matrix-Vector multiplication\n",
        "\n",
        "Случай, когда вектор не помещается в памяти Map задачи\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQhDbiL3zS9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2c56de-e861-4006-c9d5-d42fc7c2fb81"
      },
      "source": [
        "import numpy as np\n",
        "from typing import Iterator, Tuple, List\n",
        "\n",
        "# --- данные ---\n",
        "rng = np.random.default_rng(1)\n",
        "I, J = 4, 5\n",
        "M = rng.integers(0, 5, size=(I, J)).astype(float)\n",
        "v = rng.standard_normal(J).astype(float)\n",
        "\n",
        "# ---------- Шаг 1: join по j -> partials (i, M[i,j] * v[j]) ----------\n",
        "\n",
        "def RECORDREADER1():\n",
        "    # поток матрицы\n",
        "    for i in range(I):\n",
        "        for j in range(J):\n",
        "            yield ((\"M\", i, j), float(M[i, j]))\n",
        "    # поток вектора\n",
        "    for j in range(J):\n",
        "        yield ((\"V\", j), float(v[j]))\n",
        "\n",
        "def MAP1(k1, val):\n",
        "    if k1[0] == \"M\":\n",
        "        _, i, j = k1\n",
        "        yield (j, (\"M\", i, val))\n",
        "    else:\n",
        "        _, j = k1\n",
        "        yield (j, (\"V\", val))\n",
        "\n",
        "def REDUCE1(j, tagged: Iterator[Tuple]):\n",
        "    vj = None\n",
        "    m_list = []\n",
        "\n",
        "    for rec in tagged:\n",
        "        tag = rec[0]\n",
        "        if tag == \"V\":\n",
        "            vj = rec[1]\n",
        "        else:\n",
        "            # (\"M\", i, mij)\n",
        "            m_list.append((rec[1], rec[2]))\n",
        "\n",
        "    if vj is None:\n",
        "        return\n",
        "\n",
        "    for i, mij in m_list:\n",
        "        yield (i, mij * vj)\n",
        "\n",
        "partials = list(MapReduce(RECORDREADER1, MAP1, REDUCE1))\n",
        "\n",
        "# ---------- Шаг 2: sum по i -> итоговый y ----------\n",
        "\n",
        "def RECORDREADER2():\n",
        "    for i, contrib in partials:\n",
        "        yield (i, contrib)\n",
        "\n",
        "def MAP2(i, contrib):\n",
        "    yield (i, contrib)\n",
        "\n",
        "def REDUCE2(i, contribs: Iterator[float]):\n",
        "    s = 0.0\n",
        "    for x in contribs:\n",
        "        s += x\n",
        "    yield (i, s)\n",
        "\n",
        "result = list(MapReduce(RECORDREADER2, MAP2, REDUCE2))\n",
        "\n",
        "# приводим к вектору в порядке i\n",
        "result_sorted = [val for (i, val) in sorted(result, key=lambda x: x[0])]\n",
        "\n",
        "reference = (M @ v).tolist()\n",
        "print(\"Matches numpy:\", np.allclose(result_sorted, reference))\n",
        "\n",
        "result_sorted, reference"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matches numpy: True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([-1.7107315971207244,\n",
              "  -1.403993662229911,\n",
              "  -0.6630982531657752,\n",
              "  0.22407526846560044],\n",
              " [-1.7107315971207244,\n",
              "  -1.4039936622299112,\n",
              "  -0.6630982531657752,\n",
              "  0.22407526846560044])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIo2t7nNxvA9"
      },
      "source": [
        "## Matrix multiplication (Перемножение матриц)\n",
        "\n",
        "Если у нас есть матрица $M$ с элементами $m_{ij}$ в строке $i$ и столбце $j$, и матрица $N$ с элементами $n_{jk}$ в строке $j$ и столбце $k$, тогда их произведение $P = MN$ есть матрица $P$ с элементами $p_{ik}$ в строке $i$ и столбце $k$, где\n",
        "\n",
        "$$p_{ik} =\\sum_{j} m_{ij}n_{jk}$$\n",
        "\n",
        "Необходимым требованием является одинаковое количество столбцов в $M$ и строк в $N$, чтобы операция суммирования по  $j$ была осмысленной. Мы можем размышлять о матрице, как об отношении с тремя атрибутами: номер строки, номер столбца, само значение. Таким образом матрица $M$ предстваляется как отношение $ M(I, J, V )$, с кортежами $(i, j, m_{ij})$, и, аналогично, матрица $N$ представляется как отношение $N(J, K, W)$, с кортежами $(j, k, n_{jk})$. Так как большие матрицы как правило разреженные (большинство значений равно 0), и так как мы можем нулевыми значениями пренебречь (не хранить), такое реляционное представление достаточно эффективно для больших матриц. Однако, возможно, что координаты $i$, $j$, и $k$ неявно закодированы в смещение позиции элемента относительно начала файла, вместо явного хранения. Тогда, функция Map (или Reader) должна быть разработана таким образом, чтобы реконструировать компоненты $I$, $J$, и $K$ кортежей из смещения.\n",
        "\n",
        "Произведение $MN$ это фактически join, за которым следуют группировка по ключу и аггрегация. Таким образом join отношений $M(I, J, V )$ и $N(J, K, W)$, имеющих общим только атрибут $J$, создаст кортежи $(i, j, k, v, w)$ из каждого кортежа $(i, j, v) \\in M$ и кортежа $(j, k, w) \\in N$. Такой 5 компонентный кортеж представляет пару элементов матрицы $(m_{ij} , n_{jk})$. Что нам хотелось бы получить на самом деле, это произведение этих элементов, то есть, 4 компонентный кортеж$(i, j, k, v \\times w)$, так как он представляет произведение $m_{ij}n_{jk}$. Мы представляем отношение как результат одной MapReduce операции, в которой мы можем произвести группировку и аггрегацию, с $I$ и $K$  атрибутами, по которым идёт группировка, и суммой  $V \\times W$.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MBkGaLAYVCt"
      },
      "source": [
        "# MapReduce model\n",
        "def flatten(nested_iterable):\n",
        "  for iterable in nested_iterable:\n",
        "    for element in iterable:\n",
        "      yield element\n",
        "\n",
        "def groupbykey(iterable):\n",
        "  t = {}\n",
        "  for (k2, v2) in iterable:\n",
        "    t[k2] = t.get(k2, []) + [v2]\n",
        "  return t.items()\n",
        "\n",
        "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
        "  return flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER())))))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMspsOT0ZB35"
      },
      "source": [
        "Реализуйте перемножение матриц с использованием модельного кода MapReduce для одной машины в случае, когда одна матрица хранится в памяти, а другая генерируется RECORDREADER-ом."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psP1XekbsEjS"
      },
      "source": [
        "import numpy as np\n",
        "I = 2\n",
        "J = 3\n",
        "K = 4*10\n",
        "small_mat = np.random.rand(I,J)\n",
        "big_mat = np.random.rand(J,K)\n",
        "\n",
        "def RECORDREADER():\n",
        "  for j in range(big_mat.shape[0]):\n",
        "    for k in range(big_mat.shape[1]):\n",
        "      yield ((j,k), big_mat[j,k])\n",
        "\n",
        "def MAP(k1, v1):\n",
        "  (j, k) = k1\n",
        "  w = v1\n",
        "  for i in range(small_mat.shape[0]):\n",
        "    yield ((i, k), small_mat[i, j] * w)\n",
        "\n",
        "def REDUCE(key, values):\n",
        "  (i, k) = key\n",
        "  s = 0.0\n",
        "  for x in values:\n",
        "    s += x\n",
        "  yield ((i, k), s)\n",
        "\n",
        "reference_solution = small_mat @ big_mat"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnt306LHhHrm"
      },
      "source": [
        "Проверьте своё решение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewy_ZNYqW5a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d331bf5c-ebfc-49a1-a367-4c05fa8620d7"
      },
      "source": [
        "def asmatrix(reduce_output):\n",
        "  reduce_output = list(reduce_output)\n",
        "  I = max(i for ((i,k), vw) in reduce_output)+1\n",
        "  K = max(k for ((i,k), vw) in reduce_output)+1\n",
        "  mat = np.empty(shape=(I,K))\n",
        "  for ((i,k), vw) in reduce_output:\n",
        "    mat[i,k] = vw\n",
        "  return mat\n",
        "\n",
        "sol_list = list(MapReduce(RECORDREADER, MAP, REDUCE))\n",
        "\n",
        "print(\"len =\", len(sol_list), \"expected =\", I*K)\n",
        "np.allclose(reference_solution, asmatrix(sol_list))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len = 80 expected = 80\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK7v4CEcfxqf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "380de2bf-04d9-4469-8f3b-125e64858423"
      },
      "source": [
        "reduce_output = list(MapReduce(RECORDREADER, MAP, REDUCE))\n",
        "max(i for ((i,k), vw) in reduce_output)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4yyg3kOZqJJ"
      },
      "source": [
        "Реализуйте перемножение матриц  с использованием модельного кода MapReduce для одной машины в случае, когда обе матрицы генерируются в RECORDREADER. Например, сначала одна, а потом другая."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B7rIAJCaHZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b2e938d-271b-4717-b6d6-5acc51bda536"
      },
      "source": [
        "import numpy as np\n",
        "from typing import Iterator, Iterable, Tuple, Any\n",
        "\n",
        "# MapReduce model (1 machine)\n",
        "def flatten(nested_iterable: Iterable[Iterable[Any]]):\n",
        "    for iterable in nested_iterable:\n",
        "        for element in iterable:\n",
        "            yield element\n",
        "\n",
        "def groupbykey(iterable: Iterable[Tuple[Any, Any]]):\n",
        "    t = {}\n",
        "    for (k2, v2) in iterable:\n",
        "        t[k2] = t.get(k2, []) + [v2]\n",
        "    return t.items()\n",
        "\n",
        "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
        "    return flatten(\n",
        "        map(lambda x: REDUCE(*x),\n",
        "            groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER()))))\n",
        "    )\n",
        "\n",
        "# Data\n",
        "np.random.seed(0)\n",
        "\n",
        "I = 2\n",
        "J = 3\n",
        "K = 4 * 10\n",
        "\n",
        "# матрицы как \"отношения\": M(I,J,V) и N(J,K,W)\n",
        "M = np.random.rand(I, J)\n",
        "N = np.random.rand(J, K)\n",
        "\n",
        "reference_solution = M @ N\n",
        "\n",
        "# join по j -> partial products ((i,k), m_ij * n_jk)\n",
        "def RECORDREADER1():\n",
        "    # сначала матрица M: (i, j, v)\n",
        "    for i in range(I):\n",
        "        for j in range(J):\n",
        "            yield ((\"M\", i, j), float(M[i, j]))\n",
        "    # потом матрица N: (j, k, w)\n",
        "    for j in range(J):\n",
        "        for k in range(K):\n",
        "            yield ((\"N\", j, k), float(N[j, k]))\n",
        "\n",
        "def MAP1(k1, v1):\n",
        "    tag = k1[0]\n",
        "    if tag == \"M\":\n",
        "        _, i, j = k1\n",
        "        # ключ = j\n",
        "        yield (j, (\"M\", i, v1))\n",
        "    else:\n",
        "        _, j, k = k1\n",
        "        # ключ = j\n",
        "        yield (j, (\"N\", k, v1))\n",
        "\n",
        "def REDUCE1(j, tagged_values: Iterator[tuple]):\n",
        "    left = []   # (i, m_ij)\n",
        "    right = []  # (k, n_jk)\n",
        "\n",
        "    for rec in tagged_values:\n",
        "        if rec[0] == \"M\":\n",
        "            _, i, mij = rec\n",
        "            left.append((i, mij))\n",
        "        else:\n",
        "            _, k, njk = rec\n",
        "            right.append((k, njk))\n",
        "\n",
        "    # все пары (i,k): m_ij * n_jk\n",
        "    for (i, mij) in left:\n",
        "        for (k, njk) in right:\n",
        "            yield ((i, k), mij * njk)\n",
        "\n",
        "partials = list(MapReduce(RECORDREADER1, MAP1, REDUCE1))\n",
        "print(\"partials:\", len(partials), \"expected:\", I * J * K)\n",
        "\n",
        "# sum по (i,k)\n",
        "def RECORDREADER2():\n",
        "    for (ik, val) in partials:\n",
        "        yield (ik, val)\n",
        "\n",
        "def MAP2(ik, val):\n",
        "    yield (ik, val)\n",
        "\n",
        "def REDUCE2(ik, vals: Iterator[float]):\n",
        "    s = 0.0\n",
        "    for x in vals:\n",
        "        s += x\n",
        "    yield (ik, s)\n",
        "\n",
        "solution = list(MapReduce(RECORDREADER2, MAP2, REDUCE2))\n",
        "\n",
        "\n",
        "# Проверка\n",
        "def asmatrix_fixed(reduce_output, I: int, K: int):\n",
        "    mat = np.zeros((I, K), dtype=float)\n",
        "    for ((i, k), vw) in reduce_output:\n",
        "        mat[i, k] = vw\n",
        "    return mat\n",
        "\n",
        "mat_mr = asmatrix_fixed(solution, I, K)\n",
        "\n",
        "print(\"Matches numpy:\", np.allclose(reference_solution, mat_mr))\n",
        "mat_mr, reference_solution"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "partials: 240 expected: 240\n",
            "Matches numpy: True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.7060119 , 0.63824768, 1.10162159, 1.03070567, 1.03432976,\n",
              "         1.00623835, 1.09806791, 1.0127371 , 0.36281538, 0.27360563,\n",
              "         0.83172078, 0.65022457, 1.26021813, 0.65511526, 1.0593353 ,\n",
              "         0.68027906, 1.16581408, 1.10716395, 0.3554435 , 0.96219216,\n",
              "         1.02270104, 0.93282535, 1.02015213, 0.87058284, 1.11305592,\n",
              "         1.27026841, 1.3705311 , 0.92382741, 1.02955307, 0.60599253,\n",
              "         1.06928367, 0.77491501, 1.26121579, 0.87653767, 0.8618777 ,\n",
              "         0.8383055 , 1.00503923, 0.91647496, 1.02664221, 0.92337048],\n",
              "        [0.66552633, 0.60120798, 1.03071682, 0.96324559, 0.87872607,\n",
              "         0.90507802, 0.81337471, 1.01024534, 0.31412369, 0.23413706,\n",
              "         0.66653439, 0.5739761 , 1.15696681, 0.58063984, 1.03837862,\n",
              "         0.65660558, 1.00436702, 1.10531101, 0.308397  , 0.87703102,\n",
              "         0.80832492, 0.92548577, 0.78343287, 0.88202985, 0.84662929,\n",
              "         1.16710363, 1.11414771, 0.75808858, 0.84905803, 0.60924202,\n",
              "         1.02243256, 0.76251954, 1.20920135, 0.86911406, 0.79904238,\n",
              "         0.73743833, 1.02483269, 0.74213446, 0.87711888, 0.86951864]]),\n",
              " array([[0.7060119 , 0.63824768, 1.10162159, 1.03070567, 1.03432976,\n",
              "         1.00623835, 1.09806791, 1.0127371 , 0.36281538, 0.27360563,\n",
              "         0.83172078, 0.65022457, 1.26021813, 0.65511526, 1.0593353 ,\n",
              "         0.68027906, 1.16581408, 1.10716395, 0.3554435 , 0.96219216,\n",
              "         1.02270104, 0.93282535, 1.02015213, 0.87058284, 1.11305592,\n",
              "         1.27026841, 1.3705311 , 0.92382741, 1.02955307, 0.60599253,\n",
              "         1.06928367, 0.77491501, 1.26121579, 0.87653767, 0.8618777 ,\n",
              "         0.8383055 , 1.00503923, 0.91647496, 1.02664221, 0.92337048],\n",
              "        [0.66552633, 0.60120798, 1.03071682, 0.96324559, 0.87872607,\n",
              "         0.90507802, 0.81337471, 1.01024534, 0.31412369, 0.23413706,\n",
              "         0.66653439, 0.5739761 , 1.15696681, 0.58063984, 1.03837862,\n",
              "         0.65660558, 1.00436702, 1.10531101, 0.308397  , 0.87703102,\n",
              "         0.80832492, 0.92548577, 0.78343287, 0.88202985, 0.84662929,\n",
              "         1.16710363, 1.11414771, 0.75808858, 0.84905803, 0.60924202,\n",
              "         1.02243256, 0.76251954, 1.20920135, 0.86911406, 0.79904238,\n",
              "         0.73743833, 1.02483269, 0.74213446, 0.87711888, 0.86951864]]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXyzQi1DaIwo"
      },
      "source": [
        "Реализуйте перемножение матриц с использованием модельного кода MapReduce Distributed, когда каждая матрица генерируется в своём RECORDREADER."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDM_s78Rb5eR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e690e31-5679-400d-e845-2e9e29999ae2"
      },
      "source": [
        "from typing import Iterator, Tuple, Iterable, List\n",
        "import numpy as np\n",
        "\n",
        "# Данные\n",
        "np.random.seed(123)\n",
        "\n",
        "I, J, K = 3, 4, 6\n",
        "A = np.random.randn(I, J).astype(float)\n",
        "B = np.random.randn(J, K).astype(float)\n",
        "\n",
        "reference = A @ B\n",
        "\n",
        "n_maps = 4\n",
        "\n",
        "def split_list(items: List, n_chunks: int) -> List[List]:\n",
        "    n_chunks = max(1, int(n_chunks))\n",
        "    if not items:\n",
        "        return [[] for _ in range(n_chunks)]\n",
        "    size = int(np.ceil(len(items) / n_chunks))\n",
        "    return [items[i:i + size] for i in range(0, len(items), size)]\n",
        "\n",
        "# Каждая матрица имеет свой собственный СЧИТЫВАТЕЛЬ записей\n",
        "def RECORDREADER_A() -> Iterable[Tuple[Tuple[str, int, int], float]]:\n",
        "    for i in range(I):\n",
        "        for j in range(J):\n",
        "            yield ((\"A\", i, j), float(A[i, j]))\n",
        "\n",
        "def RECORDREADER_B() -> Iterable[Tuple[Tuple[str, int, int], float]]:\n",
        "    for j in range(J):\n",
        "        for k in range(K):\n",
        "            yield ((\"B\", j, k), float(B[j, k]))\n",
        "\n",
        "# Соединение по j -> частичному ((i,k), a_ij*b_jk)\n",
        "def INPUTFORMAT1():\n",
        "    a_items = list(RECORDREADER_A())\n",
        "    b_items = list(RECORDREADER_B())\n",
        "\n",
        "    # делим число мапов между A и B (хотя бы по 1)\n",
        "    a_maps = max(1, n_maps // 2)\n",
        "    b_maps = max(1, n_maps - a_maps)\n",
        "\n",
        "    a_chunks = split_list(a_items, a_maps)\n",
        "    b_chunks = split_list(b_items, b_maps)\n",
        "\n",
        "    def record_reader(chunk):\n",
        "        for (k1, v1) in chunk:\n",
        "            yield (k1, v1)\n",
        "\n",
        "    # A -> отдельно\n",
        "    for ch in a_chunks:\n",
        "        yield record_reader(ch)\n",
        "    # B -> отдельно\n",
        "    for ch in b_chunks:\n",
        "        yield record_reader(ch)\n",
        "\n",
        "def MAP1(k1, v1):\n",
        "    tag = k1[0]\n",
        "    if tag == \"A\":\n",
        "        _, i, j = k1\n",
        "        yield (j, (\"A\", i, float(v1)))\n",
        "    else:\n",
        "        _, j, k = k1\n",
        "        yield (j, (\"B\", k, float(v1)))\n",
        "\n",
        "def REDUCE1(j: int, tagged_vals: Iterator[tuple]):\n",
        "    left = []   # (i, a_ij)\n",
        "    right = []  # (k, b_jk)\n",
        "\n",
        "    for rec in tagged_vals:\n",
        "        if rec[0] == \"A\":\n",
        "            _, i, aij = rec\n",
        "            left.append((i, aij))\n",
        "        else:\n",
        "            _, k, bjk = rec\n",
        "            right.append((k, bjk))\n",
        "\n",
        "    for (i, aij) in left:\n",
        "        for (k, bjk) in right:\n",
        "            yield ((i, k), aij * bjk)\n",
        "\n",
        "stage1 = MapReduceDistributed(INPUTFORMAT1, MAP1, REDUCE1)\n",
        "stage1 = [(pid, list(part)) for (pid, part) in stage1]\n",
        "partials = [kv for (pid, part) in stage1 for kv in part]\n",
        "\n",
        "print(\"partials:\", len(partials), \"expected:\", I * J * K)\n",
        "\n",
        "\n",
        "# Суммируем по (i,k)\n",
        "def INPUTFORMAT2():\n",
        "    chunks = split_list(partials, n_maps)\n",
        "\n",
        "    def record_reader(chunk):\n",
        "        for (ik, val) in chunk:\n",
        "            yield (ik, float(val))\n",
        "\n",
        "    for ch in chunks:\n",
        "        yield record_reader(ch)\n",
        "\n",
        "def MAP2(ik, val: float):\n",
        "    yield (ik, float(val))\n",
        "\n",
        "def REDUCE2(ik, vals: Iterator[float]):\n",
        "    s = 0.0\n",
        "    for x in vals:\n",
        "        s += x\n",
        "    yield (ik, s)\n",
        "\n",
        "# combiner = reduce для суммы\n",
        "stage2 = MapReduceDistributed(INPUTFORMAT2, MAP2, REDUCE2, COMBINER=REDUCE2)\n",
        "stage2 = [(pid, list(part)) for (pid, part) in stage2]\n",
        "out = [kv for (pid, part) in stage2 for kv in part]\n",
        "\n",
        "def asmatrix_fixed(pairs, I: int, K: int):\n",
        "    mat = np.zeros((I, K), dtype=float)\n",
        "    for ((i, k), v) in pairs:\n",
        "        mat[i, k] = v\n",
        "    return mat\n",
        "\n",
        "solution = asmatrix_fixed(out, I, K)\n",
        "\n",
        "print(\"Matches numpy:\", np.allclose(reference, solution))\n",
        "solution, reference"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36 key-value pairs were sent over a network.\n",
            "partials: 72 expected: 72\n",
            "72 key-value pairs were sent over a network.\n",
            "Matches numpy: True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.5874928 ,  5.11380282,  4.14255381,  2.6082553 , -4.76484305,\n",
              "         -1.18364575],\n",
              "        [ 3.94761745,  3.75539973,  0.03318505,  6.48030108, -2.87972044,\n",
              "          2.84220932],\n",
              "        [ 1.89320179, -0.44552041, -1.64920108, -0.80574251,  3.6109436 ,\n",
              "          2.35067158]]),\n",
              " array([[-0.5874928 ,  5.11380282,  4.14255381,  2.6082553 , -4.76484305,\n",
              "         -1.18364575],\n",
              "        [ 3.94761745,  3.75539973,  0.03318505,  6.48030108, -2.87972044,\n",
              "          2.84220932],\n",
              "        [ 1.89320179, -0.44552041, -1.64920108, -0.80574251,  3.6109436 ,\n",
              "          2.35067158]]))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuSA2P9Db6UM"
      },
      "source": [
        "Обобщите предыдущее решение на случай, когда каждая матрица генерируется несколькими RECORDREADER-ами, и проверьте его работоспособность. Будет ли работать решение, если RECORDREADER-ы будут генерировать случайное подмножество элементов матрицы?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehN0FqRDcwU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4311a87f-91bf-418f-beea-e2661a5344c3"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from typing import Iterator, List, Tuple\n",
        "\n",
        "\n",
        "# Перемножение матриц через MapReduceDistributed\n",
        "# Случай: каждая матрица генерируется НЕ одним, а несколькими RECORDREADER-ами,\n",
        "# причём каждому RECORDREADER-у достаётся СЛУЧАЙНОЕ подмножество элементов,\n",
        "# но В СУММЕ покрытие ПОЛНОЕ (ничего не теряем и не дублируем).\n",
        "np.random.seed(4)\n",
        "\n",
        "I, J, K = 4, 5, 3\n",
        "A = np.random.randn(I, J).astype(float)\n",
        "B = np.random.randn(J, K).astype(float)\n",
        "\n",
        "reference = A @ B\n",
        "\n",
        "# параметры \"распределённой\" модели (если среда использует глобальные maps/reducers)\n",
        "maps = 6\n",
        "reducers = 3\n",
        "\n",
        "\n",
        "# Готовим списки всех элементов матриц (полное покрытие)\n",
        "# A: ключ (\"A\", i, j), значение a_ij\n",
        "# B: ключ (\"B\", j, k), значение b_jk\n",
        "A_entries = [((\"A\", i, j), float(A[i, j])) for i in range(I) for j in range(J)]\n",
        "B_entries = [((\"B\", j, k), float(B[j, k])) for j in range(J) for k in range(K)]\n",
        "\n",
        "\n",
        "# Функция: случайно перемешать элементы и порезать на n_splits частей\n",
        "# потерь нет, дубликатов нет — просто случайное распределение индексов\n",
        "def random_splits(entries: List[Tuple[tuple, float]], n_splits: int, seed: int):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = np.arange(len(entries))\n",
        "    rng.shuffle(idx)  # случайная перестановка индексов\n",
        "    split_idx = np.array_split(idx, n_splits)\n",
        "    return [[entries[i] for i in part] for part in split_idx]\n",
        "\n",
        "# Делаем несколько RECORDREADER-ов для каждой матрицы\n",
        "A_splits = random_splits(A_entries, n_splits=3, seed=10)\n",
        "B_splits = random_splits(B_entries, n_splits=3, seed=20)\n",
        "\n",
        "# Выдаём несколько RECORDREADER-ов\n",
        "# Сначала сплиты A, затем сплиты B (так как в условии “например, сначала одна, потом другая”)\n",
        "def INPUTFORMAT1():\n",
        "    def RR(split):\n",
        "        for kv in split:\n",
        "            yield kv\n",
        "\n",
        "    for split in A_splits:\n",
        "        yield RR(split)\n",
        "    for split in B_splits:\n",
        "        yield RR(split)\n",
        "\n",
        "\n",
        "# Шаг 1: JOIN по j и генерация частичных произведений\n",
        "# На выходе: ((i, k), a_ij * b_jk)\n",
        "def MAP1(k1, val):\n",
        "    tag = k1[0]\n",
        "    if tag == \"A\":\n",
        "        _, i, j = k1\n",
        "        # ключ для join — j\n",
        "        yield (j, (\"A\", i, val))\n",
        "    else:\n",
        "        _, j, k = k1\n",
        "        # ключ для join — j\n",
        "        yield (j, (\"B\", k, val))\n",
        "\n",
        "def REDUCE1(j, tagged_values: Iterator[tuple]):\n",
        "    left = [(i, aij) for (tag, i, aij) in tagged_values if tag == \"A\"]\n",
        "    right = [(k, bjk) for (tag, k, bjk) in tagged_values if tag == \"B\"]\n",
        "\n",
        "    # декартово произведение внутри одного j: получаем все (i,k)\n",
        "    for (i, aij) in left:\n",
        "        for (k, bjk) in right:\n",
        "            yield ((i, k), aij * bjk)\n",
        "\n",
        "stage1 = MapReduceDistributed(INPUTFORMAT1, MAP1, REDUCE1, COMBINER=None)\n",
        "stage1 = [(pid, list(part)) for (pid, part) in stage1]\n",
        "partials = [kv for (pid, part) in stage1 for kv in part]\n",
        "\n",
        "print(\"partials:\", len(partials), \"ожидалось:\", I * J * K)\n",
        "\n",
        "\n",
        "# Шаг 2: суммирование по ключу (i,k)\n",
        "# Можно тоже случайно раздать partials по map-сплитам\n",
        "maps = 4\n",
        "reducers = 3\n",
        "\n",
        "def INPUTFORMAT2():\n",
        "    rng = np.random.default_rng(30)\n",
        "    idx = np.arange(len(partials))\n",
        "    rng.shuffle(idx)\n",
        "\n",
        "    split_size = int(math.ceil(len(partials) / maps)) if partials else 1\n",
        "\n",
        "    def RR(index_chunk):\n",
        "        for t in index_chunk:\n",
        "            yield partials[t]\n",
        "\n",
        "    for i0 in range(0, len(idx), split_size):\n",
        "        yield RR(idx[i0:i0 + split_size])\n",
        "\n",
        "def MAP2(key, val):\n",
        "    yield (key, float(val))\n",
        "\n",
        "def REDUCE2(key, vals: Iterator[float]):\n",
        "    s = 0.0\n",
        "    for x in vals:\n",
        "        s += x\n",
        "    yield (key, s)\n",
        "\n",
        "# COMBINER = REDUCE2 уменьшает “трафик” (суммирует локально на mapper-е)\n",
        "stage2 = MapReduceDistributed(INPUTFORMAT2, MAP2, REDUCE2, COMBINER=REDUCE2)\n",
        "stage2 = [(pid, list(part)) for (pid, part) in stage2]\n",
        "P = [kv for (pid, part) in stage2 for kv in part]\n",
        "\n",
        "# Преобразуем список пар ((i,k), v) в матрицу I x K\n",
        "def asmatrix(pairs, I, K):\n",
        "    mat = np.zeros((I, K), dtype=float)\n",
        "    for ((i, k), v) in pairs:\n",
        "        mat[i, k] = v\n",
        "    return mat\n",
        "\n",
        "solution = asmatrix(P, I, K)\n",
        "\n",
        "print(\"Совпадает с numpy (полное покрытие, случайные RR):\", np.allclose(reference, solution))\n",
        "solution, reference"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35 key-value pairs were sent over a network.\n",
            "partials: 60 ожидалось: 60\n",
            "36 key-value pairs were sent over a network.\n",
            "Совпадает с numpy (полное покрытие, случайные RR): True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-3.30359593,  2.7572802 , -0.5851318 ],\n",
              "        [ 2.8464065 ,  0.29702452,  1.91922881],\n",
              "        [-0.29012046,  1.87650961,  2.21872797],\n",
              "        [ 2.02448215, -3.63157051,  2.6886677 ]]),\n",
              " array([[-3.30359593,  2.7572802 , -0.5851318 ],\n",
              "        [ 2.8464065 ,  0.29702452,  1.91922881],\n",
              "        [-0.29012046,  1.87650961,  2.21872797],\n",
              "        [ 2.02448215, -3.63157051,  2.6886677 ]]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}